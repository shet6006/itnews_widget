const puppeteer = require("puppeteer");
const fs = require("fs");
const path = require("path");

// âœ… Windowsì—ì„œ Chrome ì‹¤í–‰ íŒŒì¼ ì°¾ê¸°
function findChromeWin() {
    const chromePaths = [
        "C:\\Program Files\\Google\\Chrome\\Application\\chrome.exe",
        "C:\\Program Files (x86)\\Google\\Chrome\\Application\\chrome.exe",
        path.join(process.env.LOCALAPPDATA, "Google\\Chrome\\Application\\chrome.exe"),
        "C:\\Program Files\\Chromium\\Application\\chrome.exe"
    ];

    for (const chromePath of chromePaths) {
        if (fs.existsSync(chromePath)) {
            console.log(`âœ… Found Chrome at: ${chromePath}`);
            return chromePath;
        }
    }

    console.warn("âŒ Chrome not found in default paths.");
    return null;
}

// âœ… Puppeteer ì‹¤í–‰ ì‹œ Chrome ê²½ë¡œ ì ìš©
async function launchBrowser() {
    let executablePath = findChromeWin();

    // Chromeì´ ì—†ìœ¼ë©´ Puppeteer ê¸°ë³¸ ë¸Œë¼ìš°ì € ì‚¬ìš©
    if (!executablePath) {
        try {
            executablePath = puppeteer.executablePath();
        } catch (error) {
            console.error("âŒ Puppeteer Chrome not found.");
            return null;
        }
    }

    const browser = await puppeteer.launch({
        headless: "new",
        executablePath,
    });

    return browser;
}

// âœ… Hacker News í¬ë¡¤ë§
async function fetchHackerNews() {
    try {
        console.log("ğŸ” Starting Hacker News crawling...");
        const browser = await launchBrowser();
        if (!browser) return [];

        const page = await browser.newPage();
        await page.goto("https://news.ycombinator.com/", { waitUntil: "networkidle2" });

        let articles = await page.evaluate(() => {
            return [...document.querySelectorAll(".title a")]
                .slice(0, 3)
                .map(element => ({
                    title: element.innerText.trim(),
                    url: element.href,
                    source: "Hacker News"
                }));
        });

        await browser.close();
        console.log("âœ… Hacker News crawling completed:", articles);
        return articles;
    } catch (error) {
        console.error("âŒ Failed to crawl Hacker News:", error);
        return [];
    }
}

// âœ… Dev.to í¬ë¡¤ë§
async function fetchDevTo() {
    try {
        console.log("ğŸ” Starting Dev.to crawling...");
        const browser = await launchBrowser();
        if (!browser) return [];

        const page = await browser.newPage();
        await page.goto("https://dev.to/", { waitUntil: "networkidle2" });

        let articles = await page.evaluate(() => {
            return [...document.querySelectorAll(".crayons-story__title a")]
                .slice(0, 3)
                .map(element => ({
                    title: element.innerText.trim(),
                    url: element.href,
                    source: "Dev.to"
                }));
        });

        await browser.close();
        console.log("âœ… Dev.to crawling completed:", articles);
        return articles;
    } catch (error) {
        console.error("âŒ Failed to crawl Dev.to:", error);
        return [];
    }
}

// âœ… Velog í¬ë¡¤ë§
async function fetchVelog() {
    try {
        console.log("ğŸ” Starting Velog crawling...");
        const browser = await launchBrowser();
        if (!browser) return [];

        const page = await browser.newPage();
        await page.goto("https://velog.io/", { waitUntil: "networkidle2" });

        let articles = await page.evaluate(() => {
            return [...document.querySelectorAll(".PostCard_block__FTMsy")]
                .slice(0, 3)
                .map(postElement => {
                    let linkElement = postElement.querySelectorAll("a")[1];
                    let url = linkElement ? linkElement.getAttribute("href") : "#";
                    let titleElement = linkElement?.querySelector("h4");
                    let title = titleElement ? titleElement.innerText.trim() : "No Title";

                    if (!url.startsWith("https")) {
                        url = "https://velog.io" + url;
                    }

                    return { title, url, source: "Velog" };
                });
        });

        await browser.close();
        console.log("âœ… Velog crawling completed:", articles);
        return articles;
    } catch (error) {
        console.error("âŒ Failed to crawl Velog:", error);
        return [];
    }
}

// âœ… AWS ë¸”ë¡œê·¸ í¬ë¡¤ë§
async function fetchAWS() {
    try {
        console.log("ğŸ” Starting AWS crawling...");
        const browser = await launchBrowser();
        if (!browser) return [];

        const page = await browser.newPage();
        await page.goto("https://aws.amazon.com/ko/blogs/aws/page/2/", { waitUntil: "networkidle2" });

        let articles = await page.evaluate(() => {
            return [...document.querySelectorAll(".blog-post")]
                .slice(0, 3)
                .map(post => {
                    const titleElement = post.querySelector("h2");
                    const urlElement = post.querySelector("a");

                    return {
                        title: titleElement ? titleElement.textContent.trim() : "No Title",
                        url: urlElement ? urlElement.href : "No Link",
                        source: "AWS"
                    };
                });
        });

        await browser.close();
        console.log("âœ… AWS crawling completed:", articles);
        return articles;
    } catch (error) {
        console.error("âŒ Failed to crawl AWS:", error);
        return [];
    }
}

// âœ… 4ê°œ ì‚¬ì´íŠ¸ ë‰´ìŠ¤ í†µí•© í¬ë¡¤ë§
async function fetchNews() {
    console.log("ğŸ” Starting news crawling...");

    const results = await Promise.allSettled([
        fetchHackerNews(),
        fetchDevTo(),
        fetchVelog(),
        fetchAWS()
    ]);

    const allNews = results
        .filter(result => result.status === "fulfilled")
        .flatMap(result => result.value);

    console.log("ğŸ“° Final crawled news:", allNews);
    return allNews;
}

// âœ… ì¤‘ë³µ ì‹¤í–‰ ë°©ì§€ë¥¼ ìœ„í•´ ìë™ ì‹¤í–‰ ì½”ë“œ ì œê±°
module.exports = { fetchNews };
